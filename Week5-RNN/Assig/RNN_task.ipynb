{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uddLVyS5w-X",
        "outputId": "cd5f87e2-f5ff-4f47-d350-35c8461a6501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-24 12:24:22--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-24 12:24:22 (40.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()\n",
        "\n",
        "\n",
        "\n",
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qwgjFg5w-c"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7pDdsmR5w-g",
        "outputId": "1f1b6e63-45f8-4c8e-e645-d2c27fe1bdea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: tensorflow 1.15.0\n",
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "Collecting tensorflow==1.15.0\n",
            "  Using cached tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.44.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n",
            "Installing collected packages: tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorflow-1.15.0\n",
            "Collecting keras==2.1.6\n",
            "  Using cached Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.18.5)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.0.6\n",
            "    Uninstalling Keras-2.0.6:\n",
            "      Successfully uninstalled Keras-2.0.6\n",
            "Successfully installed keras-2.1.6\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.18.5)\n",
            "1.15.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.1.6\n",
        "!pip install install h5py==2.10.0\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYxCHsI_5w-i"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8AKUoCl5w-s"
      },
      "outputs": [],
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = '#'\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LR56NyI5w-w",
        "outputId": "786aa9ef-724f-45cc-ab0c-8d13c6aac4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ]
        }
      ],
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ejs9EDSg5w-z",
        "outputId": "577951a0-fbca-442b-a66a-ace20091c6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NlI4TkY5w-1"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIi0QePu5w-3",
        "outputId": "bae088be-fd88-41f6-ad9f-d4463c1f8533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ]
        }
      ],
      "source": [
        "# all unique characters go here, padding included!\n",
        "\n",
        "tokens = set(''.join(names[:]))### YOUR CODE HERE\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h2xjD4c5w-4"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x28BwKFh5w-4"
      },
      "outputs": [],
      "source": [
        "# create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "token_to_id = {} \n",
        "for i in range(n_tokens):\n",
        "    token_to_id[tokens[i]] = i\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bH-T1Zc5w-5"
      },
      "outputs": [],
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQmUBB-95w-6",
        "outputId": "3b3aa7bd-094d-4f34-c802-925767d92b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[31 29  0 47  5 47 34 48  0]\n",
            " [31 13 48 17 27 21  0  0  0]\n",
            " [31  6 27 41 39 39 41 34  0]\n",
            " [31 13 41 17 46 47 42 42 34]]\n"
          ]
        }
      ],
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YJDK6XY5w-7"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqacRUdv5w-7",
        "outputId": "50cccf34-cb2d-4800-e0e4-3815f15620f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:89: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:92: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:96: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh7GO_OT5w-8"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGtcg1Gz5w-8"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqSdCa5R5w-9"
      },
      "outputs": [],
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPJ9dSI15w-9"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDzZgU1r5w--"
      },
      "outputs": [],
      "source": [
        "! pip install -U numpy==1.18.5 # your code\n",
        "\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7TNfBTU5w--"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAZEpk5T5w-_"
      },
      "outputs": [],
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VOJieNe5w-_"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKWfXSZI5w-_",
        "outputId": "d131c50c-1fc3-492d-9d39-800ed32f4224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3014: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "loss =  tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIAmqelr5w_A"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "MRu8FwOJ5w_A",
        "outputId": "631bb7dd-3eba-465f-cba5-68944e497dd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e+bmUkhlFBCL6F3AemigCgK2JctoKviqtjWvgUb1l1dd1dW1/2prN214KorKCoWUIqCUqUKSA0IhF5C+vn9MfdOpmYmyYSQO+/nefIwc+fO3HMz4Z0z7z3nPWKMQSmlVM2XVN0NUEopFR8a0JVSyiE0oCullENoQFdKKYfQgK6UUg7hrq4DN2rUyGRlZVXX4ZVSqkZasmTJXmNMZrjHqi2gZ2VlsXjx4uo6vFJK1UgisjXSY5pyUUoph9CArpRSDqEBXSmlHKLacuhKKRUPhYWFZGdnk5eXV91NiavU1FRatmyJx+OJ+Tka0JVSNVp2djZ16tQhKysLEanu5sSFMYZ9+/aRnZ1N27ZtY36eplyUUjVaXl4eDRs2dEwwBxARGjZsWO5vHTEHdBFxicgyEfkwzGMpIjJNRDaKyCIRySpXK5RSqhKcFMxtFTmn8vTQbwXWRnjsauCAMaYDMAX4S7lbEqPsA7k8+MFqCotLquoQSilVI8UU0EWkJXAe8HyEXS4CXrFuvwOcJVX0kblm52FeWrCFlxdsqYqXV0qpcqtdu3Z1NwGIvYf+D+APQKRucQtgO4Axpgg4BDQM3klEJorIYhFZnJOTU4HmwshuTRjRpTFTPl/P7sPOuqqtlFKVETWgi8j5wB5jzJLKHswYM9UY088Y0y8zM2wpgqhEhPsv6EZRseGvs36obJOUUipujDH8/ve/p0ePHvTs2ZNp06YB8NNPPzF06FB69+5Njx49mDdvHsXFxUyYMMG375QpUyp9/FiGLQ4BLhSRMUAqUFdE/mOM+bXfPjuAVkC2iLiBesC+SrcugjYN05kwJIt/z9vENWe0pUvTulV1KKVUDfLgB6tZs/NwXF+zW/O63H9B95j2fe+991i+fDkrVqxg79699O/fn6FDh/LGG29w7rnncs8991BcXExubi7Lly9nx44drFq1CoCDBw9Wuq1Re+jGmLuMMS2NMVnAOGB2UDAHmAFcad3+ubVPlS5WeuPw9niSknj7u+yqPIxSSsVs/vz5jB8/HpfLRZMmTRg2bBjfffcd/fv356WXXuKBBx5g5cqV1KlTh3bt2rFp0yZuvvlmPvnkE+rWrXzHtMITi0TkIWCxMWYG8ALwmohsBPbjDfxVKqNWMmd2yeSD73dyz3ldcSU5b9iSUqp8Yu1Jn2hDhw5l7ty5zJw5kwkTJnDHHXdwxRVXsGLFCmbNmsWzzz7L22+/zYsvvlip45RrYpEx5ktjzPnW7clWMMcYk2eM+YUxpoMxZoAxZlOlWhWji3q3IOdIPku2HjgRh1NKqTKdccYZTJs2jeLiYnJycpg7dy4DBgxg69atNGnShGuvvZZrrrmGpUuXsnfvXkpKShg7diyPPPIIS5curfTxa/TU/yHtGyECCzftY0DbBtXdHKVUgrvkkkv45ptv6NWrFyLC448/TtOmTXnllVf461//isfjoXbt2rz66qvs2LGDq666ipIS7+DBRx99tNLHlypOdUfUr18/E48FLkY/OY8G6R5ev2ZQHFqllKpp1q5dS9euXau7GVUi3LmJyBJjTL9w+9f4Wi69W2WweudhquuDSSmlThY1PqB3blKbg7mF5BzNr+6mKKVUtarxAb1T0zoArN91tJpbopSqLk78hl6Rc6rxAb1jY29A37jnSDW3RClVHVJTU9m3b5+jgrpdDz01NbVcz6vRo1wAGtVOxuMSdh/RlItSiahly5ZkZ2dT0fpQJyt7xaLyqPEBXUTIrJ1CjgZ0pRKSx+Mp16o+TlbjUy4AmXVS2KMBXSmV4BwS0FO1h66USngOCegp5BzR2uhKqcTmmIC+71gBRbosnVIqgTkioDeuk4IxsO9YQXU3RSmlqo0jAnpmnRQAzaMrpRKaowL6Hs2jK6USmCMCesP0ZAAOHCus5pYopVT1cURAT0/xzo86VlBUzS1RSqnq44iAXtsK6EfyNKArpRKXIwJ6ijsJd5JwLF8DulIqcTkioIsI6SlujmpAV0olMEcEdPCmXTSgK6USmaMCuqZclFKJzDEBPT3FpT10pVRCixrQRSRVRL4VkRUislpEHgyzzwQRyRGR5dbPNVXT3Mhqp3o4ml98og+rlFInjVgWuMgHRhhjjoqIB5gvIh8bYxYG7TfNGPPb+DcxNrVTXOw8eLy6Dq+UUtUuakA33oX67BWYPdbPSbd4X3qym6M6Dl0plcBiyqGLiEtElgN7gM+MMYvC7DZWRL4XkXdEpFWE15koIotFZHG81/+rnaoXRZVSiS2mgG6MKTbG9AZaAgNEpEfQLh8AWcaYU4DPgFcivM5UY0w/Y0y/zMzMyrQ7RKrHRV6R5tCVUomrXKNcjDEHgTnAqKDt+4wxdu3a54G+8Wle7JJdSRQWG0pKTrpskFJKnRCxjHLJFJEM63YaMBJYF7RPM7+7FwJr49nIWCS7vadSoKsWKaUSVCyjXJoBr4iIC+8HwNvGmA9F5CFgsTFmBnCLiFwIFAH7gQlV1eBIkl2lAT3V4zrRh1dKqWoXyyiX74E+YbZP9rt9F3BXfJtWPnYPvbBIe+hKqcTkmJmimnJRSiU65wR0O+WiPXSlVIJyTkB3a0BXSiU2xwX0fA3oSqkE5biArjl0pVSick5A1xy6UirBOSegaw5dKZXgnBPQrR56oaZclFIJyjkBXXvoSqkE57yArj10pVSCck5Ad+mwRaVUYnNMQE/RlItSKsE5JqBrDl0plegcE9A9Ls2hK6USm2MCupbPVUolOscEdHeSIKI9dKVU4nJMQBcRkl1JmkNXSiUsxwR08KZddNiiUipROSqgp7iTNOWilEpYjgromnJRSiUyZwV0twZ0pVTiclRA92gPXSmVwBwV0JPdSVo+VymVsBwX0PWiqFIqUUUN6CKSKiLfisgKEVktIg+G2SdFRKaJyEYRWSQiWVXR2GiSXTpsUSmVuGLpoecDI4wxvYDewCgRGRS0z9XAAWNMB2AK8Jf4NjM2elFUKZXIogZ043XUuuuxfkzQbhcBr1i33wHOEhGJWytjlKIBXSmVwGLKoYuIS0SWA3uAz4wxi4J2aQFsBzDGFAGHgIZhXmeiiCwWkcU5OTmVa3kYmkNXSiWymAK6MabYGNMbaAkMEJEeFTmYMWaqMaafMaZfZmZmRV6iTDqxSCmVyMo1ysUYcxCYA4wKemgH0ApARNxAPWBfPBpYHh5XEkXaQ1dKJahYRrlkikiGdTsNGAmsC9ptBnCldfvnwGxjTHCevcp53EkUFJ/wwyql1EnBHcM+zYBXRMSF9wPgbWPMhyLyELDYGDMDeAF4TUQ2AvuBcVXW4jIku3RikVIqcUUN6MaY74E+YbZP9rudB/wivk0rP49LNKArpRKWo2aKurWHrpRKYI4K6B5XEoXFhmpI3yulVLVzVEBPdnnnMhXqhVGlVAJyVED3uLynU1SiaRelVOJxZEAvLNIeulIq8TgroLu9p6PT/5VSichZAT3JzqFrQFdKJR5nBXQ75aIBXSmVgJwV0N0a0JVSictRAV2HLSqlEpmjArqmXJRSiUwDulJKOYQjA3qBjkNXSiUghwV0HbaolEpcDgvomnJRSiUuhwZ0TbkopRKPowJ6sltTLkqpxOWogK4pF6VUItOArpRSDuGogO62RrkUaA5dKZWAHBXQk3310LWHrpRKPI4K6JpyUUolMkcG9KISTbkopRJP1IAuIq1EZI6IrBGR1SJya5h9hovIIRFZbv1Mrprmls2eKVqgKRelVAJyx7BPEXCnMWapiNQBlojIZ8aYNUH7zTPGnB//JsZORPC4RFMuSqmEFLWHboz5yRiz1Lp9BFgLtKjqhlWUOylJA7pSKiGVK4cuIllAH2BRmIcHi8gKEflYRLpHeP5EEVksIotzcnLK3dhYeHvomkNXSiWemAO6iNQG3gVuM8YcDnp4KdDGGNML+CfwfrjXMMZMNcb0M8b0y8zMrGiby5TsTqJAe+hKqQQUU0AXEQ/eYP66Mea94MeNMYeNMUet2x8BHhFpFNeWxsjjSqJIA7pSKgHFMspFgBeAtcaYJyLs09TaDxEZYL3uvng2NFYeV5KmXJRSCSmWUS5DgMuBlSKy3Np2N9AawBjzLPBz4AYRKQKOA+OMMdUSVT0u0ZSLUiohRQ3oxpj5gETZ52ng6Xg1qjI8riSd+q+USkiOmikKdspFA7pSKvE4MKDrsEWlVGJyYEDXHrpSKjE5LqAnuzWgK6USk+MCug5bVEolKgcGdC3OpZRKTI4L6G6XTv1XSiUmxwX0ZL0oqpRKUI4L6B6XUKQ5dKVUAnJgQNceulIqMTkyoOsSdEqpROS4gO4dh64pF6VU4nFcQHcn6bBFpVRiclxA97iSKCoxlJRoL10plVgcF9CT3d5TKizRXrpSKrE4LqB7XN7S7Tp0USmVaBwY0K0euubRlVIJxrEBPV+HLiqlEozjAnqaxwVAXmFxNbdEKaVOLOcF9GQ7oGsPXSmVWBwX0FM93lM6rj10pVSCcWBA9/bQjxdoQFdKJRbHBXRfDr1IA7pSKrFEDegi0kpE5ojIGhFZLSK3htlHROQpEdkoIt+LyKlV09zo7B56nvbQlVIJxh3DPkXAncaYpSJSB1giIp8ZY9b47TMa6Gj9DASesf494eweuubQlVKJJmoP3RjzkzFmqXX7CLAWaBG020XAq8ZrIZAhIs3i3toY6CgXpVSiKlcOXUSygD7AoqCHWgDb/e5nExr0EZGJIrJYRBbn5OSUr6UxSnVrD10plZhiDugiUht4F7jNGHO4Igczxkw1xvQzxvTLzMysyEtElZrsPSWdWKSUSjQxBXQR8eAN5q8bY94Ls8sOoJXf/ZbWthMu2ZVEkmhAV0olnlhGuQjwArDWGPNEhN1mAFdYo10GAYeMMT/FsZ0xExFSPS4dh66USjixjHIZAlwOrBSR5da2u4HWAMaYZ4GPgDHARiAXuCr+TY1dmselOXSlVMKJGtCNMfMBibKPAW6KV6MqK9Xj0lEuSqmE47iZouCt56I5dKVUonFkQE9L1pSLUirxODKgp7pdvh76rW8t49SHP2P1zkPV3CqllKpajgzo/j306ct3sv9YAec9Nb+aW6WUUlXLkQFdhy0qpRKRYwO6rimqlEo0jgzoaZ6kkB56ulW0SymlnMqRAd3tSmLX4TyO5Rf5ttlVGAuLS/AOm1dKKWdxZEB/d0k2ALe+tdy3rX6tZPYdzafjPR/z0oIt1dQypZSqOo4M6H3b1Afg87W7fdvyi0rYeTAPgHeXZsf8Wo98uIbBj34R3wYqpVQVcGRA/8vYU0K25VdwjdHn52/mp0N5lW2SUkpVOUcG9LppnpBteYUlSJkVacpWUqJ5d6XUyc2RAd1eV9SWWSeF/KLigIuk5XWkEs9VSqkTwZEB3eMK7Ir3aF6XvMISfjV1YYVf8/Dxwso2SymlqpQjA7oE5VZ6tcqIuG9uQVFMlRkP52lAV0qd3BwZ0IN5XIGnuXHPUT5e6V1QqdvkWYz6x9wynuv9cNByvEqpk51jA/rEoe18t4NTMPlFJdzw+lJWbD8IwJZ9ueQcySe/qJjnvvqRo375cleS97nHC7SUgFLq5BbLEnQ10jWnt2Xq3E1AaA/ddtG/Fvhu9//T59RKdpFbUMz2A7k8cnFP33PzCku0h66UOuk5toee4i4d6RIpoAfLteq/HDhWmi+3n6sLZiilTnbODeie0lMLTrlEU+w35txOuQT30HcdyqPH/bNYt+twJVqplFLx49iAnuzyD+jlO80iv4Buv05wQJ+9bg9H84t4OUpdmJwj+WRNmsmCjXvL1QallCovxwb0JKtnfUbHRuUO6HYNmFMf/owdB48D3pmmtvW7j/Dnj9Za28tOxayylr57zsrn2/IKi8maNJP3ylFXRimlyuLYgA6wYNII/n1Fv4CAfmbnzJifv/9Yge+2fw59wovf+kbCRMut17JmrR4vCJxpuvuwtz7ME5+tj7k9SilVFkcH9BYZaaR6XAE59Beu7F+h1/ph1xHfbf8yAP499/wib6/7X3M2+rYlu72/4tygBTfskuyVqS+jlFL+ogZ0EXlRRPaIyKoIjw8XkUMistz6mRz/ZlaOfw/dTsVEE7wIxvrdR3wFuvxrwvj30A9Z5QH+OusHvrDSNiXW66zeGXjx1F4iL0kjulIqTmLpob8MjIqyzzxjTG/r56HKNyu+gtMip3do5Lvds0W9sM/pcM/HAfc37DlKu7s/4o/vfI9/4cXDxwt9y93l5pce5+pXFgNQWBy+SqPdJg3nSql4iRrQjTFzgf0noC1VpkPj2gDcd343AMb2bQHAqa0z+ODm08M+pzhCudxpi7cH3F+36whdJ38CwD6/nLutKExAX7H9IBdbk5qC684A7Dmcx5a9x8IeP5z9xwr48oc9Ufc7klfo+xahlHKeeOXQB4vIChH5WES6R9pJRCaKyGIRWZyTkxOnQ0fXPrM2mx8dw9WntwVKUzDhgmlFvb9sB2Of+Tpke2FJaY59+vId7D6cx3y/IYwC3DFtOb0f+tS3bcCfv2D4376M+dhXvLiICS99F3XETc8HPqXXg5+WuY9SquaKx9T/pUAbY8xRERkDvA90DLejMWYqMBWgX79+J3TFCP/g7U4K/zk24bQs3EnC8/M3+7aN6t6UNg1rhQw7DHbbtOVhtxf79dBvfWs5HpcEpGH25xbw3rIdEV9358HjTJ6+mifH9SY9JfDtWrH9IM3qpbJqhzc/X1BcQmpQLXjwVpQ8mKs9c6WcrtI9dGPMYWPMUev2R4BHRBpFeVq1SnZ7g3tw//yBC7vTuWmdgG3DOmfy2xEdKnSckhJDUUlgUa/gnLp/oC0qLuGQ3/1l2w5ww3+W8Pna3XyyalfI61/0rwWM+PtXvvv5heELiF3670Wc9tjsCp2DUqrmqHRAF5GmYnV/RWSA9Zr7Kvu6Val2ineJui7N6oQ85g4qE1Ar2UWd1NAl7WLx4oLNES+KhnPP/1bRyy/1csn/fc2K7ENh22XzrwxZUBw+oC+3qkracgsqt/rSrkN5vPnttkq9hlIq/qKmXETkTWA40EhEsoH7AQ+AMeZZ4OfADSJSBBwHxpngMX8nmX5t6vPmtYPo1rwu4K3MONu6qHgsPzAP3SA9ucLHeXH+ZvpmNYh5/+ALrv6C00Rb94VeNM2PsYDYfe+v5u+/7BVzu4Ld9MZSlmw9wLBOmTTPSKvw6yil4itqQDfGjI/y+NPA03Fr0QmQlCQMbt/Qd//e87txrzUC5kheYO81OKB/ctsZjPrHvJiOs/NQHjtX7Kxka71cScKAP33OWV2bMKxTI67/z9KQfeyx7YfzCtlx4Dhdm9UN+1rbD+RWqi32OPwDuQVxD+hPfr6Bz9bu4sObz4jr6yqVCBw9U7QimtZLCbifUSswoHdpWpcPfls61PGf4/uQUcvDud2b0D+rfrmO1aIcwTBJYM+RfN78dhu//+/3Yfd5d0k2JSWGUx74lNFPzguZHGULztWXV0Ytbwoq2hDIldmH+NVz35SrlvyUz9f7LvIqpcrHsQtcVNTFvVvQIqMWGbU8vLFoG83qpgLwwAXdfCNIXH6zTc8/pRkX9Gruu581aWbMx3LFOGsVAi+m+pce8Pf8/M0BI3SKSgyfrg69mLp020F6PfQpL1/Vn+GdGwOwZe8xikpK6NA49LpCsHppVkAP+lCYsWIn2/fnctOZ3ovIk2esYtm2g6zeeZi+bcr3YaeUKj8N6EFEhAFtvXnvBy4sHVI/YUhb323/kSvBY9lTPUkB9V3K4i5HQLerO4ZTJ8UdNsjvOHCcSe+G780DTHjpOyaN7kJWw3Su/88SALY8dl7UttgfbMH1aW55cxmAL6Db4/0LI1ysVUrFl6ZcKqDAylX3C9PrXHLvSKb8KrYLjs9e3pfrhrZjQAwXTu0yvuG0qB8+dTP8b19G7M3bHvt4nS+Y20pKjK9uTTh2/ZlogdquJf/lDyduEplt+faDzIjT9QulagoN6BXQPtNbSuCaM9qGPJae4uaSPi1Z+cA5IY8N6dAw4H6nJnW4a0xXLhvUulLtaVYvtVLP97fnSB6XPPM1ne/7OOI+9veKSe+tZOGmfdw/fVXYUgl2lctnv/qRRZsij2S1q1S+6JcuitWMFTvJmjSTI3mB6Z+L/7XA941BqUShAb0C6qcns+Wx8xjVo1nEfWqnhGazuvmNOvn9uZ19t9OsFMbAtrEPcfTXtF78RpoM+NMXrNh+kMJiw8rsQ2zbVzoiZuu+YxzMLQhIM42bupBXvtnKqh2HfNvsce7+VS5/NXVhxGMePu7d/5+zN/i22R8QhcXeBbqf/epH/htmWOfT1nPK+gZTHTbuOap1c9QJpzn0KiIifHb7UEZOmevb5j9B6doz2vlut7eKh23bX7HhhE3rxq+H7u+Cp+cDMPvOYSzbdpA7/7sCgJ/1aRGy72sLt/pud5s8iyd+2QuPO7b+gl2t0v8icWFxCa4kF7967huWbiudGPWLfq18t4tLDOt3Hy3ztY0xca3ZE6uzn/iKdpnpzL5z+Ak/tkpc2kOvQu0yazOufyum3zSEW87qyMSh7Zg41BvI/RfdyGqYzoC2DfjL2FN820Z0aRzxdf916an88MgoLh3oTdXUT6/YTNZYjfj7V75gDrDgx9D1URdtDkypvLFoG54wF32Xbz8YkHsvLC7h6TneXrZ/bXh7XVf/YB7subk/+m5Hmspmj82vDptyYq+YqVQ8aECvQq4k4bGxp9CrVQZ3jOxEqsfF3WO6suWx8wJ6ja4k4e3rBjO0U+nyeJNGd+Hq09vy8MU9GNe/FQ9fVDriZljnTFLcLn4zJItWDdIY1aNpTO1pVDsl+k4xCB7dArB9f2DKY/HWA7y/PPCi5Lpdh7n4Xwv426wfADhwrICO93zM24u966r699CLYhgZs/an0lWkiooN2Qdyfb1922mPzebQ8cKw5YhX7TjE+t1HQrbH6mh+ETlH8iv8/JrqaH4RV730LdmVnKB2ImzYfYSsSTNZtu1AdTflhNCAfpLq1KQO953fjcsHteGxsadw+eAs32N2zr1D4zrM+8MIGteJLeUSPGmqooJn08bq189/C8Can7wTh74JulAamHIx7D0ae7D8cOVOTv/LHG5+c5lvtSjw1oof+8zXYcsRn//P+ZzjlxLz979l2RzM9da3n7V6F1mTZrIhKPif99Q8+v/p85DnVmfliz1H8siaNJNvN1fdEgafrNrFnB9ymPLZhug7l0MsH+LlNXudt6THRyt/ivtrh7Nxz5EKXdyPFw3oJ5lYZo+WZ0KSv/Tk6r1kYgdou6BY8Dh8//vH8ovo90j4YLlxzxEuf2ER2/zq2Tz3lbe88edrd/tWi7Jt3HPU91xjDF//uDfssMw1Ow/zrzkb+XrjXm6ftoKbrVEyf5rpnQMwcsrcgFmvW/eF76GWpyCbv1U7DpE1aSYLyxgRFM13m7090ZcWeIPK5r3HIi7WUlH2sooV/DMMa8veY3S45+OIQ0035Rxl+vLIZaYjsU/9RCz1uOdIHmc/MZeHPlwT9995rDSgn2Rm3nI6n98xLOxjZY2C+cOozrRuUIvpNw3hd+d0CrtPcD318jq3e5Oo+zz6s54Bo3nCWbbtIJ+s2hXyweRfZiFSjfi9RwsY+8w3zNuw11eJMlbHC4t5b+kOLv33IqavKH39o/lFXPnit4x5ah5/nfUDlz6/CIB5G/ZSXGIwlP7n7HLfJwEjegC+Wp/Dve+v9N33n3j2/LzSOvrb9+cGpCnsEgyz1+3GGOML5P6lkr217AvYvj+33L3MbftyOfNvXzLls/WAdxGWrvd9QkFRCdkHctm67xglJYaXF2z2fejFwvgCevmC5MJN+3wjoCZPX8Uf3im9LmN/a/vQCugrsw8FXGsZ9eQ8bn0r/JoDZbE/fCpzYfzrH/fy/LxNAWsJh3Prm6XtK6imazc6yuUkk1ErOaR+jO2V3wwIyRHbbhzegRuHe2do9mqVwd8+Xc/oHk3ZezSf77Z4e221kl28fFV/vs8+xMC2DcocShhOg/RkshrWYkuEninA+AGtWbL1gO8/aCTf/LiXge0Cx+X7/5/bFqaaJBA2xRGrI3lFfP2jN2j6V9Xscf+siM/5z8KtIRdcl207QA+/tWivfNGbSpp8fneS3UkBPfRHZq7lmjPaceh4IWc8Pgfwzsaduz6HW95a5quH/9T4Pr5hni9/vYXLB7ehRUYaE176jm8376dOqpsjeUVMmziIXq0yAhYy2bL3GMP/9iUp7iTfRWAR2HfM+43oy/V7+N25nXn8k3UcLyxm9+E8X1vSPC6OFxbz874t+dsvYpsQZ3c+Z63ZRfu56Uwc2p4dB4+z53AebRqmh61Qmn0gl3FTF3Jhr+Y8Nb4Pr37jHRX1+M+9x/QPt5v3HuOCp+cz4bQs32xtO0AWFZfgdiVRUFSCO0miLvpufAE9+nntO5rPT4fyAt7b3YfzuPTf3g/4nKP53DW6a8TnH/abC/H52t0MaNuAJlU0Ai0SDeg1SKrHFXZFonA2/mk0SeL9g3/z223c9d5K0pPdDO/c2Fe/5Y6RnXjC6r3Z3rl+MNO+285/l2QzpmdTzujoLZG7fX8uF/VuzrgYPgRKYsghv/LNVl75ZmvANv/aMEej9IYqYuCfv/DN7o217ML9M1b7atfYnv1qE298GzomvtO9HzPrtqH81broazuaX8SQoAVGrrA+BGy7Dh0P+Ab1xdrd/Pmjdb779nUL+0N48vnd+I21pOLcDd6ZuP4jeowpfR/shU/qpnnYeSgv4NqEvVj5O0uyeWdJNuseHhX1b8x+3YO5hfz5o3VMHNqeoY/P8aUZFkwaEZI6tNNTM1bsDAh8k6evYmDbhizZWnrR0r52sdS6kDnz+9JvJrmFxdR1JdHpXu/Et9l3DqOdNdHvWH5RyLdQ40u5lHlKgBOQXswAABJiSURBVHfBmOwDxwPKXxQE/U7DueCf8+ndKgO337yLm99cRouMNBZMGuE7lw6Na1O3gmsrxEpTLg7ldiX5ei/2V8XgP/ZbzipdKXBcf+/47uYZab6Zp5cOaMP4Aa0Z1imTXw9qQ51UD7WSo3+g1Ak6Tiy9o8sGtmaT30iUz9dGX/S6In7Y5b2wOem9lVH2LBU8QWjHweOsjfANZNWOQ3zud1EWYOjjcwI+oMJNOFq/+yj3/G+V7/4zX/4Yso+/hz5cw/WvLWHL3mNMnr465PHdh/NYZg35tAN9XeuD6ZL/C1371pZ9IHSCVl5hMTe+voTNe49x6HhhyMLneYXFATnjIY/NDqg9ZIzhMiuNBYGlIF79Zis3vbGUF62cv6G09n9RseFgbgE3vVFaKjo3v5hXvt7iuz/2ma9ZsHEvvR78lO73zwpZzMUe/rph99GoKRP73P0vzvoH8cygUWIlJYYte4+xcschXlu4NWSYrj3ZraCohJ/939dcE3RtpypoQE8Adv6wYe3Ii3U8cGF3Prz5dJpnpHHjmR146ar+nN4xdCXB20eGz88DzPvDmQC0bZQesH38gOilDWL95hEs+FjRRKttU1mfrgmtbrn/WEHA/Yc+WBOyz6ygqpgHYihv/MnqXREXE1+67SCPWBdzc47k8+xXP/LToeizaedtyGH68h1kTZrp60kv2XqAj1bu4g/vrKDXg59y/4zAD5Au930S8jpT527yPb88cwG++iGHrfu9H+zFJSZkiOyybQcCjn8gt5DLnl/k+5D8IOii6pNfeEfifLpmN9e95q1ZNOeHPfxnYeC3w6e+KB2x4z+Ky38VsOBVw578YkPA7z/SqmJ5Rd5z+Hbz/nKN3KoIDegJ4NeDWnPHyE5ha89cZk1OSvW4fLnDVI+LMzuHn9h0Wvvwy8W2y0ynVYNa1vHacM3ppcdqFiWPOOVXvUj1lP4pxvItwDZ+QKvoO51As1bvjrrP4bzQYF3RoaCxOF5YzGMfrwuZKxDOgo17edYaMXTpvxeSNWmm7/0o69pJOKc84F1OsTz18AuKS/jtG97RRev3HAlZSzcnxoC4btfhkFLW8zfu5a73VnLVS99x7/ul34aMMQGpR//3x//CbPCFzgUbAyfY+Ze68Oe/1u/tERaTjxcN6Akgxe3ilrM6kuIODZR/uqRnTCVzo3H55VXcriSuG9bed3/isHbcPaYL6x4eFfK8Ry7uwSV9WnL9sPYkW6UC7A+TsgK7nRbKLyyJOGHqtPYNeXFCP+4e06X8JwQMalex2jrRfLYmetCvLsUlxpdvthcasdePrcgkqgdmrGbv0YLoO4ZhjDe15G/P4bLb8ML8zeQXFUdcVcx/LVz7gunTszcG7GPXFnp3SXZAbn//sQLeW5rNrkN5ABQHJdWTIwR0/w+0iv4uYqUBXZVb07qptMhICyj7GzwE0f+PO8XtYuLQ9iFplSZ1U/j1oDaAt87Ns78+FYCBViBNCaoF86dLevhu926VAUDjuik8d3lfX0kFf29cO4gRXZowrFPkMgqRJAk8Oa5PuZ8XbEzP2GbxnixyC4pDhiPaM3kr4uWvt3DP/2K/XhHN22Wsu2tbszO2Fa/swB089v2Cp+eTNWkmd/53RUBP/rm5m7jj7RVc/oL3ekDwXIZwF/L/u3g7+UWlAb24pGqHM2pAV+X2zV0jmP/HM3nj2oF8evtQwDuz1V9yDIW5Ft19dsD9EV2a8OOfx3Catd5ritvFM5edysC2DRjeOZPLBrbh4Yu9Qf2u0V154cp+/KJvK/q2qc/dYyIPJwtuSy/rw6As6x4eHdDzH9mtdAx+ndTYB4dd2Cu0kFlZ/n1Fv3LtH2+LNu+P+4Iki+I4a3VPDN8S7B50NN9s2sfhvELfSJ9YbdhzlNveWsZPQccJd56/f+f7gJo+VT3hSAO6KjcRQURwu5Lo1KQOr/xmAI+N7Rmwj118LFKt9v/deFrY7a4koZY1o7Vjk9qM7tmMadcN5uWrBgDw64GtWTH5HFo3rMVZXZtEHYcMgQG9U5PaNK0bvQRCsjsp4FvH6R281w5uHtGBv8c4XhsgLdlFO+vCbWadso9bN9XNyG5N+OiW0AWym8ex5r0t0nms2xW9vo1/+eeTzQ8x1ue5/j9L6Pfw5yGBORbvL98Z04cLwHV+C8j8mHOM/y2r+DeeaDSgq0ob1inTF4RtblcST47rzTs3BAbux37Wk8HtGtKndeQ1RptnpPHP8X345/jQlIeIUK9W+cby+le2/PT2Yb7Uz3k9m/lSNxf2as6zv+4b8twnftmL35/bmcsGtuaPo7pw4/AODGzbkLaN0nnu8r6+IH3Tme257eyOXD+sPV2aln5bSfO4+N+NQ5jzu+FcF5QWuu3sjgH37YvS3ZrX9Y2T/+z2oWx57Dw+vm1owL5/HNWFd28YTLtM74fFQ37F22I1tm/Lcj/HVjfNw5Pjeof9ncXqy98Np7H1+7t0YGvfmO1oPC5hcNCkNPubIsA/Pi8dsWIPx42koLiE4hLDKS3r8ea1g2JterkEj1+/fdoK9hwu/4dILHRikaoyF/UOTTeMG9CacTEMY/RfeLuyUlyBufsxPZsxfflObj27I52a1OFofhGp7iTcriTm//FMdvv9Z/vZqaVB74bh3gu9acku5vxuOACPfrSWHOCSPi18C2z/dkQH3+zTwuIS6tXyUK+Wh2vOaOcbSvjmtYMY3L4h1w9rz8HcQpZvP8DAtqVBqn56MjlH8n0jh4InN9lteevaQcxavYvLB2exee8xXlqwJWC/c7o1IT3FzS/6tfTNePT3zGWncsPrS0O2R9OkTgrndK/c9YGsRum+Wafndm9Ki4w0zu7aOOochCQRXrqqv2+45FldGtPRWlMg2Lndm/LV+pyQXvhNZ7bn9UXbfDN1R/VoWuEFZsIZ0LZBmQXSXpi/mbvKSBNWVNQeuoi8KCJ7RGRVhMdFRJ4SkY0i8r2InBr3VipVTv4BMDiHfm73pqx/ZLQv7187xe2b5deyfi36ton9P7Y9xt+/VkjtFDfvXD+YemkeugbVtXnu8r7878bTGGxdJ0j1uGhaL5VRPZpR32/K/NvXDeb+C7pFHZ/fuG6qrxLnbWeHzhFonpHGlF/1pmvTuta5B9bjGd2zGeed4l15q3vzsmvw2N8GgIC2hjPhtKwyHw9mXwC/eURHGqYns/jesyPue9OZHUj1uHy/29tHdkJEAnrpL1zZj1YN0ji1TX1+d05pesi+kF8vzcOCP5Z+I6iT4i4zfWd/gMbKfwGbcCKV96isWFIuLwOh481KjQY6Wj8TgWcq3yylys9OrXx3z9nM++OZvu3hLtDGctG2MvplNWDF/eeE1DU5t3vTMtNNtraN0rlqSOC8ATtlMzpC/ft6aR5m3TaUub8/k5cm9Gf8gNb8xnqN+unJLLr7LB68sEfI86b8sjdvXDuQ6TcNCfu6C+86i0d/1pPZdw5n9p3DuHRga/pEubB8Ue/Sb1jXDW0XsMbu42NPYZaVQrKLddkBvVerDJbcN5JGtVO42prLcEbQBDd7hvPUy/syrn8rOlspLvt6zcMX9+Csrk2Y94cR1EvzMLZvS9pbH0Y3jejApQNbc9nANqSnuH3zGOwPZHu/4N/x+P6tI/5+/D1z2am8fs1ARnZrUuZw4HhWqvQXNeVijJkrIlll7HIR8KrxDupcKCIZItLMGHNiChArZVl099nkFxWHXHysaLnhWLSsn8bmvccijkGOp7vGdI36Nd0Obq0b1uLMoFWvmtRNDTv9PdmdFHHCGEDTeqm+2b7tMmvz50t6huzTMD2Z9o1r+9IMdf2+IQW3+Zd+ee1LB7Tm+fmbfe32Z0/U8a+78+pvBvhut2pQi8f8Vvmqk+ph86NjwlZWfHJcH/7yyToGtm3AML+FZOz8tv2UPq3r82POMa4d2o6L+7TguteWcN/53WjdsBatG9aiZ4t6rNxxiFNbZ/hW01r/yGg63fsxTeumMrpn5HWG/VXVWJd45NBbAP6DQ7OtbSEBXUQm4u3F07p15Va6VypYuCp/tp/1aeFLLcTTP8f3Ye6Gvb5c98kuLUoK554xXVmRfRAR4YMVO8tcCtG27L6ReNxJ1E5xM+Wz9biSJKSeTyR3j+nK787tHDa19NsR3uqhN53Znvunr+bOcztHXS8gUpncHi3q8drVA0O292xZj7e+2067Rt4c/MMX9WBg2wb0aZWBiLB88siA9IhdG+bWszv5qmwmu5OYftMQmodp22ntG/oqfL57w2mMfcZbR2dAHPP1/k7oRVFjzFRgKkC/fv2qb1kXlXCe+FXvKnndjFrJXBjHC7hVzc4TRwq41/qNxHnil70CZgBH4p9Pt2v92JNp/HP23ZvXDSkQl5QkpCaF/5CpneJm0mjvLN+qev8uHdCafm0a+L4hpCW7AhYiD8512xODGll1kezfY6S5DS9OKL1427dNfb783XCa1E0lrRzlLcojHgF9B+A/NqiltU0pdRJ69TcDAi5wRhKpNkksUtwult43kvp+Q0xnhhlfX91EJGy6J5I0a3huitvFwxd1913cjiTV42L8gFac0dGb5skqZzG58opHQJ8B/FZE3gIGAoc0f67Uyct/MfKqVFYKrKZ6enwf3lmSTfvMdDpEGCoZ7NGfnRJ9pziJGtBF5E1gONBIRLKB+wEPgDHmWeAjYAywEcgFrqqqxiqlVHVq1aBWmSWkq1sso1zGR3ncADfFrUVKKaUqRKf+K6WUQ2hAV0oph9CArpRSDqEBXSmlHEIDulJKOYQGdKWUcggN6Eop5RBigpfTOFEHFskBtlbw6Y2AvXFsTk2g55wY9JwTQ2XOuY0xJux032oL6JUhIouNMdW7mu4JpuecGPScE0NVnbOmXJRSyiE0oCullEPU1IA+tbobUA30nBODnnNiqJJzrpE5dKWUUqFqag9dKaVUEA3oSinlEDUuoIvIKBH5QUQ2isik6m5PvIhIKxGZIyJrRGS1iNxqbW8gIp+JyAbr3/rWdhGRp6zfw/cicmr1nkHFiIhLRJaJyIfW/bYissg6r2kikmxtT7Hub7Qez6rOdleGiGSIyDsisk5E1orIYCe/zyJyu/U3vUpE3hSRVCe+zyLyoojsEZFVftvK/b6KyJXW/htE5MrytKFGBXQRcQH/AkYD3YDxItKtelsVN0XAncaYbsAg4Cbr3CYBXxhjOgJfWPfB+zvoaP1MBJ458U2Oi1uBtX73/wJMMcZ0AA4AV1vbrwYOWNunWPvVVE8CnxhjugC98J6/I99nEWkB3AL0M8b0AFzAOJz5Pr8MjAraVq73VUQa4F0VbiAwALjf/hCIiTGmxvwAg4FZfvfvAu6q7nZV0blOB0YCPwDNrG3NgB+s288B4/329+1XU37wLij+BTAC+BAQvLPn3MHvNzALGGzddlv7SXWfQwXOuR6wObjtTn2fgRbAdqCB9b59CJzr1PcZyAJWVfR9BcYDz/ltD9gv2k+N6qFT+sdhy7a2OYr1NbMPsAhoYkoX3d4FNLFuO+F38Q/gD0CJdb8hcNAYU2Td9z8n3/lajx+y9q9p2gI5wEtWqul5EUnHoe+zMWYH8DdgG/AT3vdtCc5/n23lfV8r9X7XtIDueCJSG3gXuM0Yc9j/MeP9yHbEOFMROR/YY4xZUt1tOcHcwKnAM8aYPsAxSr+GA457n+sDF+H9IGsOpBOalkgIJ+J9rWkBfQfQyu9+S2ubI4iIB28wf90Y8561ebeINLMebwbssbbX9N/FEOBCEdkCvIU37fIkkCEi9uLl/ufkO1/r8XrAvhPZ4DjJBrKNMYus++/gDfBOfZ/PBjYbY3KMMYXAe3jfe6e/z7byvq+Ver9rWkD/DuhoXSFPxntxZUY1tykuRESAF4C1xpgn/B6aAdhXuq/Em1u3t19hXS0fBBzy+2p30jPG3GWMaWmMycL7Ps42xlwGzAF+bu0WfL727+Hn1v41rhdrjNkFbBeRztams4A1OPR9xptqGSQitay/cft8Hf0++ynv+zoLOEdE6lvfbs6xtsWmui8iVOCiwxhgPfAjcE91tyeO53U63q9j3wPLrZ8xePOHXwAbgM+BBtb+gnfEz4/ASryjCKr9PCp47sOBD63b7YBvgY3Af4EUa3uqdX+j9Xi76m53Jc63N7DYeq/fB+o7+X0GHgTWAauA14AUJ77PwJt4rxMU4v0mdnVF3lfgN9b5bwSuKk8bdOq/Uko5RE1LuSillIpAA7pSSjmEBnSllHIIDehKKeUQGtCVUsohNKArpZRDaEBXSimH+H/EOZOPb3lObgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAdDW7ct5w_A"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVMUAvMO5w_A"
      },
      "outputs": [],
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IooAzG3q5w_B"
      },
      "outputs": [],
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bJdZSdC5w_B",
        "outputId": "6f797414-b5a8-4bfb-c915-19c7ac0a5532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Vhizbbbbbbbbbbb\n",
            " Nethbbbbbbbbbbb\n",
            " Pyfandbbbbbbbbb\n",
            " Alebbbbbbbbbbbb\n",
            " Aldinabbbbbbbbb\n",
            " Beciybbbbbbbbbb\n",
            " Jeotiraichabbbb\n",
            " Ghenkandbbbbbbb\n",
            " Vanetbinnebbbbb\n",
            " Midelbbbbbbbbbb\n"
          ]
        }
      ],
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffW5fTJs5w_B",
        "outputId": "dbecb5e3-335b-4ae4-d6ca-15249e2613c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Trumpebbbbbbbbb\n",
            " Trumpittmibbbbb\n",
            " Trumpbbbbbbbbbb\n",
            " Trumpebbbbbbbbb\n",
            " Trumpobbbbbbbbb\n",
            " Trumpsbbbbbbbbb\n",
            " Trumpelbbbbbbbb\n",
            " Trumpkebbbbbbbb\n",
            " Trumpibbbbbbbbb\n",
            " Trumpabbbbbbbbb\n"
          ]
        }
      ],
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt01QE4y5w_B"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9-0E73-5w_C"
      },
      "outputs": [],
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = 'JlNXdRcurAjuZpYB' ### YOUR TOKEN HERE \n",
        "COURSERA_EMAIL = 'e0321294@u.nus.edu' ### YOUR EMAIL HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpSAh5xn5w_C",
        "outputId": "630d65f5-f3a1-4341-b5ae-ea3b46248e96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ],
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZVAsQn95w_C"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RmLTGVXq5w_D"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bamcyomT5w_D",
        "outputId": "7488d928-ff4d-416c-b16b-b37bf8ab2855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-932903461488>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-23-932903461488>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ]
        }
      ],
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH_4_ITI5w_E"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2de6e_95w_E",
        "outputId": "af98695a-3bf4-446b-da5e-06ee7cae1ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ]
        }
      ],
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFK3LpJ25w_E",
        "outputId": "72af893e-a566-4853-c5e1-b77e09faf8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ],
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}